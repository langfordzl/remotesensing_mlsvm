{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b253dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afa128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(path, data1):\n",
    "    f00 = gdal.Open(path + data1 + \".tif\")\n",
    "    imarray = np.array(f00.ReadAsArray())\n",
    "    #print (imarray.shape)\n",
    "    return imarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e05050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to check if images are same (could be error on my end)\n",
    "def img_to_df(mask, img):\n",
    "    print(Counter(mask.flatten()))\n",
    "    l = mask.flatten()\n",
    "    df = pd.DataFrame(data=l, columns=['label'])\n",
    "    # loop through bands and add to df\n",
    "    for i in range(0, img.shape[0]):\n",
    "        #print (i)\n",
    "        b = img[i,:,:].flatten()\n",
    "        df['b'+str(i)] = b\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06da12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(df00):\n",
    "    # remove NaNs\n",
    "    label = df00[['label']]\n",
    "    del df00['label']\n",
    "\n",
    "    # change labels\n",
    "    # -1 background 1 fire\n",
    "    label = label.astype(int).replace(0,-1)\n",
    "    label = label.astype(int).replace(1,1)\n",
    "\n",
    "    df00['label'] = label.values\n",
    "    # drops NaNs\n",
    "    df00 = df00.dropna()\n",
    "    # switch column order\n",
    "    cols = df00.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df00 = df00[cols]\n",
    "    return df00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd24519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_df(ipath, iname, mpath, mname):\n",
    "    print (mname)\n",
    "    f00 = open_image(mpath, mname)\n",
    "    m11_00 = open_image(ipath, iname)\n",
    "    df00 = img_to_df(f00, m11_00)\n",
    "    df00 = remove_nans(df00)\n",
    "    print (df00.shape)\n",
    "    return df00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9a1f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modis_2000\n",
      "fire00\n",
      "Counter({0: 4824892, 1: 7008})\n",
      "(452478, 208)\n",
      "modis_2001\n",
      "fire01\n",
      "Error 1\n",
      "modis_2002\n",
      "fire02\n",
      "Counter({0: 4818747, 1: 13153})\n",
      "(1870710, 208)\n",
      "modis_2003\n",
      "fire03\n",
      "Counter({0: 4808116, 1: 23784})\n",
      "(1261062, 208)\n",
      "modis_2004\n",
      "fire04\n",
      "Counter({0: 4823540, 1: 8360})\n",
      "(1868492, 208)\n",
      "modis_2005\n",
      "fire05\n",
      "Counter({0: 4823959, 1: 7941})\n",
      "(1471772, 208)\n",
      "modis_2006\n",
      "fire06\n",
      "Counter({0: 4812433, 1: 19467})\n",
      "(1827588, 208)\n",
      "modis_2007\n",
      "fire07\n",
      "Counter({0: 4806641, 1: 25259})\n",
      "(1964512, 208)\n",
      "modis_2008\n",
      "fire08\n",
      "Counter({0: 4795777, 1: 36123})\n",
      "(1848880, 208)\n",
      "modis_2009\n",
      "fire09\n",
      "Counter({0: 4820543, 1: 11357})\n",
      "(1854346, 208)\n",
      "modis_2010\n",
      "fire10\n",
      "Counter({0: 4828290, 1: 3610})\n",
      "(1405527, 208)\n",
      "modis_2011\n",
      "fire11\n",
      "Counter({0: 4825293, 1: 6607})\n",
      "(1600628, 208)\n",
      "modis_2012\n",
      "fire12\n",
      "Counter({0: 4811191, 1: 20709})\n",
      "(1643565, 208)\n",
      "modis_2013\n",
      "fire13\n",
      "Counter({0: 4817168, 1: 14732})\n",
      "(1963539, 208)\n",
      "modis_2014\n",
      "fire14\n",
      "Counter({0: 4817405, 1: 14495})\n",
      "(1925184, 208)\n",
      "modis_2015\n",
      "fire15\n",
      "Counter({0: 4811530, 1: 20370})\n",
      "(1894947, 208)\n",
      "modis_2016\n",
      "fire16\n",
      "Counter({0: 4817312, 1: 14588})\n",
      "(1676220, 208)\n",
      "modis_2017\n",
      "fire17\n",
      "Counter({0: 4794951, 1: 36949})\n",
      "(1827533, 208)\n",
      "modis_2018\n",
      "fire18\n",
      "Counter({0: 4793259, 1: 38641})\n",
      "(1729924, 208)\n",
      "modis_2019\n",
      "fire19\n",
      "Counter({0: 4823338, 1: 8562})\n",
      "(1646888, 208)\n",
      "modis_2020\n",
      "fire20\n",
      "Counter({0: 4734364, 1: 97536})\n",
      "(1816785, 208)\n"
     ]
    }
   ],
   "source": [
    "ipath = 'C:/Users/lql/Desktop/rs_petsc/ca_data/modis/'\n",
    "mpath = 'C:/Users/lql/Desktop/rs_petsc/ca_data/fire_rasters/'\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(0,21):\n",
    "    try:\n",
    "\n",
    "        if len(str(i)) == 1:\n",
    "            print ('modis_200' + str(i))\n",
    "            iname = 'modis_200' + str(i)\n",
    "            mname = 'fire0' + str(i)\n",
    "            df = path_to_df(ipath, iname, mpath, mname)\n",
    "            data.append(df)\n",
    "        else:\n",
    "            print ('modis_20' + str(i))\n",
    "            iname = 'modis_20' + str(i)\n",
    "            mname = 'fire' + str(i)\n",
    "            df = path_to_df(ipath, iname, mpath, mname)\n",
    "            data.append(df)\n",
    "    except:\n",
    "        print ('Error', i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7e5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pd.concat(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b291d636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    33202600\n",
       " 1      347980\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.shape\n",
    "mod['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e794c92",
   "metadata": {},
   "source": [
    "# Train/Test Sets\n",
    "* 5%, 10%, 20% data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245a6b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8124582 9802111\n",
      "(1677529, 208)\n",
      "-1    1662655\n",
      " 1      14874\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_grid(mod, percent):\n",
    "    ls = mod.shape[0]\n",
    "    am = round(ls * percent)\n",
    "    start = random.randint(0,ls-am)\n",
    "    end = start + am\n",
    "    print (start, end)\n",
    "    mod2 = mod[start:end]\n",
    "    print (mod2.shape)\n",
    "    print (mod2['label'].value_counts())\n",
    "    return mod2\n",
    "\n",
    "mod_05 = random_grid(mod, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f3f95be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8119854 11474912\n",
      "(3355058, 208)\n",
      "-1    3304210\n",
      " 1      50848\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_10 = random_grid(mod, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f220da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28218341 28889353\n",
      "(671012, 208)\n",
      "-1    646584\n",
      " 1     24428\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_02 = random_grid(mod, 0.02)\n",
    "\n",
    "sample = 30000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd56af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7749184",
   "metadata": {},
   "source": [
    "# Get Train/Test Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e873c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_grids(mod11):\n",
    "    X = mod11.copy()\n",
    "    y = mod11['label'].values\n",
    "    \n",
    "    Xtrain, Xtest, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False, random_state=42)\n",
    "    print ('Xtrain ********************')\n",
    "    print (Xtrain['label'].value_counts())\n",
    "    print ('Xtest ********************')\n",
    "    print (Xtest['label'].value_counts())\n",
    "    \n",
    "    return Xtrain, Xtest\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "658d9ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain ********************\n",
      "-1    489899\n",
      " 1     13360\n",
      "Name: label, dtype: int64\n",
      "Xtest ********************\n",
      "-1    156685\n",
      " 1     11068\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tr_mod02, te_mod02 = train_test_grids(mod_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "daa4a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<503259x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 104173150 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n",
      "(<167753x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 34724292 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\lql\\\\Desktop\\\\rs_petsc\\\\ca_data\\\\permon_data\\\\'\n",
    "name = path + 'ca_modis02_train.bin'\n",
    "df_to_petsc(tr_mod02,name)\n",
    "\n",
    "name = path + 'ca_modis02_test.bin'\n",
    "df_to_petsc(te_mod02,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbe328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain ********************\n",
      "-1    1245594\n",
      " 1      12552\n",
      "Name: label, dtype: int64\n",
      "Xtest ********************\n",
      "-1    417061\n",
      " 1      2322\n",
      "Name: label, dtype: int64\n",
      "Xtrain ********************\n",
      "-1    2489572\n",
      " 1      26721\n",
      "Name: label, dtype: int64\n",
      "Xtest ********************\n",
      "-1    814638\n",
      " 1     24127\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tr_mod05, te_mod05 = train_test_grids(mod_05)\n",
    "tr_mod10, te_mod10 = train_test_grids(mod_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c195fd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537312 8247428\n",
      "(6710116, 208)\n",
      "-1    6662542\n",
      " 1      47574\n",
      "Name: label, dtype: int64\n",
      "Xtrain ********************\n",
      "-1    4995136\n",
      " 1      37451\n",
      "Name: label, dtype: int64\n",
      "Xtest ********************\n",
      "-1    1667406\n",
      " 1      10123\n",
      "Name: label, dtype: int64\n",
      "(<5032587x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 1041743833 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n",
      "(<1677529x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 347247272 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n"
     ]
    }
   ],
   "source": [
    "mod_20 = random_grid(mod, 0.20)\n",
    "tr_mod20, te_mod20 = train_test_grids(mod_20)\n",
    "\n",
    "path = 'C:\\\\Users\\\\lql\\\\Desktop\\\\rs_petsc\\\\ca_data\\\\permon_data\\\\'\n",
    "name = path + 'ca_modis20_train.bin'\n",
    "df_to_petsc(tr_mod20,name)\n",
    "\n",
    "name = path + 'ca_modis20_test.bin'\n",
    "df_to_petsc(te_mod20,name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7fa22c",
   "metadata": {},
   "source": [
    "# Convert to PETSc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41c4d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, 'C:/Users/lql/Desktop/rs_petsc/repos/petsc/lib/petsc/bin')\n",
    "import PetscBinaryIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ccb1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d3b8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_petsc(df,name):\n",
    "    ytrain = df['label'].values\n",
    "    xtrain = df.copy()\n",
    "    del xtrain['label']\n",
    "    xtrain = xtrain.values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(xtrain)\n",
    "    xtrain = scaler.transform(xtrain)\n",
    "    sXtrain = sparse.csr_matrix(xtrain)\n",
    "    sYtrain = ytrain.view(PetscBinaryIO.Vec)\n",
    "    permon_train = (sXtrain, sYtrain)\n",
    "    print (permon_train)\n",
    "    io = PetscBinaryIO.PetscBinaryIO()\n",
    "    io.writeBinaryFile(name, permon_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33e99c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<1258146x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 260435137 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n",
      "(<419383x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 86811805 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\lql\\\\Desktop\\\\rs_petsc\\\\ca_data\\\\permon_data\\\\'\n",
    "name = path + 'ca_modis05_train.bin'\n",
    "df_to_petsc(tr_mod05,name)\n",
    "\n",
    "name = path + 'ca_modis05_test.bin'\n",
    "df_to_petsc(te_mod05,name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51cc2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<2516293x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 520871486 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n",
      "(<838765x207 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 173623216 stored elements in Compressed Sparse Row format>, Vec([-1, -1, -1, ..., -1, -1, -1]))\n"
     ]
    }
   ],
   "source": [
    "name = path + 'ca_modis10_train.bin'\n",
    "df_to_petsc(tr_mod10,name)\n",
    "\n",
    "name = path + 'ca_modis10_test.bin'\n",
    "df_to_petsc(te_mod10,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb8524",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cec0de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test xgboost \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def xgboost_pipeline(mod11, shuffle):\n",
    "    X = mod11.copy()\n",
    "    y = mod11['label'].values\n",
    "    del X['label']\n",
    "    \n",
    "    Xtrain, Xtest, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=shuffle, random_state=42)\n",
    "    \n",
    "    # fit model no training data\n",
    "    model = XGBClassifier()\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    \n",
    "    ypred = model.predict(Xtest)\n",
    "    print (classification_report(y_test, ypred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70bafd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00   1090404\n",
      "           1       0.96      0.76      0.85     16766\n",
      "\n",
      "    accuracy                           1.00   1107170\n",
      "   macro avg       0.98      0.88      0.92   1107170\n",
      "weighted avg       1.00      1.00      1.00   1107170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_pipeline(mod_10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d54317dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00    550717\n",
      "           1       0.67      0.21      0.32      2868\n",
      "\n",
      "    accuracy                           1.00    553585\n",
      "   macro avg       0.83      0.60      0.66    553585\n",
      "weighted avg       0.99      1.00      0.99    553585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_pipeline(mod_05, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df10ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00    548701\n",
      "           1       0.96      0.74      0.84      4884\n",
      "\n",
      "    accuracy                           1.00    553585\n",
      "   macro avg       0.98      0.87      0.92    553585\n",
      "weighted avg       1.00      1.00      1.00    553585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_pipeline(mod_05, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15db801",
   "metadata": {},
   "source": [
    "# Viz Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c964d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
